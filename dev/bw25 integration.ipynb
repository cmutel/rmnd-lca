{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ee4a922-7efc-48bb-bd9a-e43ebc357a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bw2data as bd\n",
    "import bw2io as bi\n",
    "import bw2calc as bc\n",
    "import premise as pr\n",
    "import bw_processing as bwp\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bbba6c9-8d4c-4368-b61b-fb13f033e690",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREMISE_KEY = os.environ[\"PREMISE_KEY\"]\n",
    "assert PREMISE_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5a5c27f-7464-43db-be57-7e94b273d74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bd.projects.set_current(\"premise bw25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a55d176d-a85f-45ba-aaf7-80f72c821177",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = \"/Users/cmutel/Documents/lca/Ecoinvent/3.7.1/cutoff/datasets\"\n",
    "\n",
    "if \"ecoinvent 3.7.1 cutoff\" not in bd.databases:\n",
    "    bi.bw2setup()\n",
    "    ei = bi.SingleOutputEcospold2Importer(fp, \"ecoinvent 3.7.1 cutoff\")\n",
    "    ei.apply_strategies()\n",
    "    assert ei.all_linked\n",
    "    ei.write_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd4fbb90-a1d2-4c7a-a46e-c36b6e4e2d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "////////////////////// EXTRACTING SOURCE DATABASE ///////////////////////\n",
      "Getting activity data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 19128/19128 [00:00<00:00, 112221.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding exchange data to activities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 621719/621719 [00:56<00:00, 10927.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling out exchange data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 19128/19128 [00:05<00:00, 3705.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set missing location of datasets to global scope.\n",
      "Set missing location of production exchanges to scope of dataset.\n",
      "Correct missing location of technosphere exchanges.\n",
      "Correct missing flow categories for biosphere exchanges\n",
      "Remove empty exchanges.\n",
      "\n",
      "/////////////////// IMPORTING DEFAULT INVENTORIES ////////////////////\n",
      "Importing necessary inventories...\n",
      "\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ndb = pr.NewDatabase(\n",
    "        scenarios=[\n",
    "                {\"model\":\"remind\", \"pathway\":\"SSP2-Base\", \"year\":2028}\n",
    "            ],\n",
    "        source_db=\"ecoinvent 3.7.1 cutoff\",\n",
    "        source_version=\"3.7.1\",\n",
    "        key=PREMISE_KEY\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59bc4e00-76bb-4328-b791-cf04ecb13446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import io\n",
    "from contextlib import redirect_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31781d6f-e3c7-41d2-ba08-cabd6262324f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Europe  not found in regex\n",
      "Europe  not found in regex\n",
      "Europe  not found in regex\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 248.21454405784607 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "# avoid printing lots of stuff; available afterwards as a buffer in capture_log\n",
    "with io.StringIO() as capture_log, redirect_stdout(capture_log):\n",
    "    ndb.update_cars()\n",
    "    ndb.update_trucks()\n",
    "    ndb.update_electricity()\n",
    "    ndb.update_cement()\n",
    "    ndb.update_steel()\n",
    "    ndb.update_solar_PV()\n",
    "\n",
    "print(\"Took {} seconds\".format(time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eb12248-14e9-483b-a0d1-045c3d17ddcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20108"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ndb.db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bfb14fd-2197-4664-b420-feb15b34cd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CHP CCS',\n",
       " 'Carma CCS',\n",
       " 'Hydrogen from biogas SMR and ATR',\n",
       " 'Hydrogen from coal Gasification',\n",
       " 'Hydrogen from woody biomass gasification',\n",
       " 'Methanol-based fuels from biogas hydrogen',\n",
       " 'Methanol-based fuels from biomass hydrogen',\n",
       " 'Methanol-based fuels from electrolysis',\n",
       " 'Methanol-based fuels from natural gas hydrogen',\n",
       " 'Methanol-based fuels with hydrogen from coal',\n",
       " 'MobiTool - other vehicles',\n",
       " 'biofuels',\n",
       " 'biogas',\n",
       " 'cement CCS-CCU',\n",
       " 'direct air capture',\n",
       " 'ecoinvent 3.7.1 cutoff',\n",
       " 'geothermal',\n",
       " 'hydrogen-electrolysis',\n",
       " 'hydrogen-smr-natgas',\n",
       " 'synfuel from FT from biomass',\n",
       " 'synfuel from FT from biomass with CCS',\n",
       " 'synfuel from FT from biomethane',\n",
       " 'synfuel from FT from hydrogen from petroleum cracking',\n",
       " 'synfuel from FT from natural gas',\n",
       " 'synfuel from FT from natural gas with CCS',\n",
       " 'synfuel from coal',\n",
       " 'synfuel from electrolysis',\n",
       " 'syngas',\n",
       " 'syngas from coal'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{o['database'] for o in ndb.db}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def532fb-9cf7-4f83-a1f7-c2a7594c4ada",
   "metadata": {},
   "source": [
    "# Create a new export function\n",
    "\n",
    "This already exists in `wurst`: [write_brightway25_database](https://github.com/polca/wurst/blob/master/wurst/brightway25/__init__.py#L30). However, `premise` doesn't follow `wurst` convention and set the `modified` flag on modified activities, so we will instead write a complete datapackage **without creating a `bw2data` database**. The metadata will only be stored in a CSV in the datapackage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "754d3b40-2c12-47c0-a6bc-28b8bb90dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wurst.linking import check_internal_linking, link_internal\n",
    "from bw2data.backends import ActivityDataset as AD\n",
    "from fs.zipfs import ZipFS\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8251b96-eee5-4ee8-bf16-e71e103a7ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatapackageWriter:\n",
    "    def __init__(self, database, filesystem, name=None, dont_write=[\"biosphere3\"], offset=100_000, **kwargs):\n",
    "        self.db = database\n",
    "        self.offset = offset\n",
    "        self.dont_write = dont_write\n",
    "        self.name = name\n",
    "        \n",
    "        if isinstance(filesystem, str):\n",
    "            self.filesystem = ZipFS(filesystem, write=True)\n",
    "        else:\n",
    "            self.filesystem = filesystem\n",
    "            \n",
    "        # Check that each activity has a production exchange\n",
    "        assert len(self.db) == sum([1 for obj in self.db if any(exc['type'] == 'production' for exc in obj['exchanges'])])\n",
    "    \n",
    "        link_internal(database) \n",
    "        check_internal_linking(database)\n",
    "        \n",
    "    def assign_ids(self):\n",
    "        database_names = {exc['input'][0] for ds in self.db for exc in ds['exchanges']}\n",
    "        id_mapping = {(ds.database, ds.code): ds.id for ds in AD.select().where(AD.database << database_names)}\n",
    "        \n",
    "        new_id_start = max(id_mapping.values()) + self.offset\n",
    "        \n",
    "        # Add ids for activities not in the bw2data database\n",
    "        for i, ds in enumerate(self.db):\n",
    "            if (ds['database'], ds['code']) not in id_mapping:\n",
    "                id_mapping[(ds['database'], ds['code'])] = new_id_start + i\n",
    "        \n",
    "        for ds in self.db:\n",
    "            col = id_mapping[(ds['database'], ds['code'])]\n",
    "            ds['id'] = col\n",
    "            for exc in ds['exchanges']:\n",
    "                exc['col'] = col\n",
    "                exc['row'] = id_mapping[exc['input']]\n",
    "\n",
    "    def get_indices(self, itr):\n",
    "        return np.array([(o['row'], o['col']) for o in itr], dtype=bwp.INDICES_DTYPE)\n",
    "    \n",
    "    def get_data(self, itr):\n",
    "        return np.array([o['amount'] for o in itr])\n",
    "    \n",
    "    def get_flip(self, itr):\n",
    "        return np.array([o['type'] in ('technosphere', 'generic consumption') for o in itr])\n",
    "                \n",
    "    def get_exchange_iterator(self, data, database_name, act_types=None, exc_types=None):\n",
    "        act_filter = lambda ds: ds.get('type') in act_types if act_types else True\n",
    "        exc_filter = lambda exc: exc.get('type') in exc_types if exc_types else True\n",
    "        return (exc \n",
    "                for ds in data \n",
    "                for exc in ds['exchanges'] \n",
    "                if ds['database'] == database_name \n",
    "                and act_filter(ds)\n",
    "                and exc_filter(exc)\n",
    "               )\n",
    "\n",
    "    def technosphere(self, data, database_name):\n",
    "        return self.get_exchange_iterator(\n",
    "            data=data,\n",
    "            database_name=database_name,\n",
    "            act_types=('process', None),\n",
    "            exc_types=('production', 'substitution', 'generic production', 'technosphere', 'generic consumption')\n",
    "        )\n",
    "\n",
    "    def biosphere(self, data, database_name):\n",
    "        return self.get_exchange_iterator(\n",
    "            data=data,\n",
    "            database_name=database_name,\n",
    "            act_types=('process', None),\n",
    "            exc_types=('biosphere',)\n",
    "        )\n",
    "\n",
    "    def write_datapackage(self, **kwargs):\n",
    "        dp = bwp.create_datapackage(fs=self.filesystem, name=self.name, **kwargs)\n",
    "        FIELDS = [\"id\", \"database\", \"code\", \"name\", \"unit\", \"location\", \"reference product\"]\n",
    "\n",
    "        for database_name in sorted({o['database'] for o in self.db}):\n",
    "            dp.add_persistent_vector(\n",
    "                matrix=\"technosphere_matrix\",\n",
    "                name=database_name + \" technosphere\",\n",
    "                indices_array=self.get_indices(self.technosphere(self.db, database_name)),\n",
    "                data_array=self.get_data(self.technosphere(self.db, database_name)),\n",
    "                flip_array=self.get_flip(self.technosphere(self.db, database_name)),\n",
    "            )\n",
    "            dp.add_persistent_vector(\n",
    "                matrix=\"biosphere_matrix\",\n",
    "                name=database_name + \" biosphere\",\n",
    "                indices_array=self.get_indices(self.biosphere(self.db, database_name)),\n",
    "                data_array=self.get_data(self.biosphere(self.db, database_name)),\n",
    "                flip_array=self.get_flip(self.biosphere(self.db, database_name)),\n",
    "            )\n",
    "            df = pd.DataFrame([{field: ds.get(field) \n",
    "                                for field in FIELDS} \n",
    "                               for ds in self.db\n",
    "                               if ds['database'] == database_name\n",
    "                              ])\n",
    "            dp.add_csv_metadata(\n",
    "                dataframe=df,\n",
    "                valid_for=[\n",
    "                    (database_name + \" technosphere\", \"cols\"),\n",
    "                    (database_name + \" biosphere\", \"cols\"),\n",
    "                ],\n",
    "                name=database_name + \" metadata\"\n",
    "            )\n",
    "        dp.finalize_serialization()\n",
    "        return dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6e0f734-e282-4599-bf07-13a1ddd22155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 34.742751121520996 / 22.46084713935852 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "dpw = DatapackageWriter(\n",
    "    database=ndb.db,\n",
    "    filesystem=\"remind SSP2-Base 2028.zip\",\n",
    "    name=\"remind SSP2-Base 2028\",\n",
    ")\n",
    "dpw.assign_ids()\n",
    "\n",
    "intermediate = time()\n",
    "\n",
    "dp = dpw.write_datapackage()\n",
    "\n",
    "now = time()\n",
    "\n",
    "print(\"Took {} / {} seconds\".format(now - start, now - intermediate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b08f845a-8db4-44ae-8b92-51567f905939",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipcc = bd.Method(('IPCC 2013', 'climate change', 'GWP 100a')).datapackage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ebb0d72-8d2a-4794-ac47-e430ba7c82df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21646"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndb.db[1000]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ea518e4-2c3b-44bf-9271-ca505c3f7b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "lca = bc.LCA({21646: 1}, data_objs=[ipcc, dp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43bd3a19-75cd-4167-b665-2722dd374118",
   "metadata": {},
   "outputs": [],
   "source": [
    "lca.lci()\n",
    "lca.lcia()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88514e97-a533-4f6a-92be-acee69541fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.588797156831066"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lca.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "714df8f6-ba3c-4204-b5eb-848cfa617826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20108x20108 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 242644 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lca.technosphere_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9a1fb68-5cb4-41e4-baa9-9830e0b6f147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2106x20108 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 390065 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lca.biosphere_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e66c6282-318f-4bfa-90fb-9d7c18f6286a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2106x2106 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 83 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lca.characterization_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8888017a-899c-4aa1-92e3-f1ad046c4271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<bw_processing.datapackage.FilteredDatapackage at 0x22d6a0d30>: [],\n",
       " <bw_processing.datapackage.FilteredDatapackage at 0x22d6a04f0>: [<matrix_utils.resource_group.ResourceGroup at 0x22d6a0640>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22d6a0760>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22d6a0190>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22d6a0550>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22d6a0910>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22d6a05e0>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22d6a0c70>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22d6a05b0>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22d6a0610>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22d6a06d0>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22c3815b0>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22dacd0a0>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22dacd100>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22dacd070>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22dacd8e0>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22dacd940>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22dacdb20>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22dacdf70>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22dacdac0>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22dacd880>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22dacdb50>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22dacdc70>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22dacda90>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22dacdaf0>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22dacd760>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22dacd700>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22dacd910>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22dacd6a0>,\n",
       "  <matrix_utils.resource_group.ResourceGroup at 0x22dacdc10>]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lca.technosphere_mm.packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29d40c4-56bb-4768-b4b9-63ac30426bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
